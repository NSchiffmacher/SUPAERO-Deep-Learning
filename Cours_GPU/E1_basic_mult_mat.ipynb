{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NSchiffmacher/SUPAERO-Deep-Learning/blob/main/Cours_GPU/E1_basic_mult_mat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exercice 1 : MATRIX MULTIPLICATION WITH PARALLELIZED COMPUTATIONS IN A SINGLE BLOC\n",
        "\n",
        "The goal of this first exercise is to get familiar with the basic concepts of GPU computing with CUDA. Note that the algorithms here won't be optimized nor computationally efficient... efficient strategies will start being studied in exercise 2.\n",
        "\n",
        "-> Remark 1: Code adapted from: https://shephexd.github.io/development/2017/02/19/pycuda.html\n",
        "\n",
        "-> Remark 2:  If using google colab:\n",
        "* Click on Runtime (excecution) and select Change runtime type (modifier le type d'excecution).\n",
        "* Then select GPU in Hardware Acceleration (accélérateur matériel)\n",
        "* Start your session by installing pycuda with the command: \\\" !pip install pycuda \\\"\n"
      ],
      "metadata": {
        "id": "3ix27r7Ezwvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycuda   #practical actually run on google colab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9u52o7Mp0qml",
        "outputId": "0bd18741-3a61-4143-8864-ca32d1bff403"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycuda\n",
            "  Downloading pycuda-2024.1.2.tar.gz (1.7 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/1.7 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytools>=2011.2 (from pycuda)\n",
            "  Downloading pytools-2024.1.18-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pycuda) (4.3.6)\n",
            "Collecting mako (from pycuda)\n",
            "  Downloading Mako-1.3.7-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mako->pycuda) (3.0.2)\n",
            "Downloading pytools-2024.1.18-py3-none-any.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.8/89.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Mako-1.3.7-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.9/78.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pycuda\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2024.1.2-cp310-cp310-linux_x86_64.whl size=660545 sha256=98ca0624b7afbca9b2294d837e86a46812fc8ee37888945120eebf495264869d\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/63/40/4bf006182f942d3516b71bb2ff3b57ccbdb8b2c0ee81882b6e\n",
            "Successfully built pycuda\n",
            "Installing collected packages: pytools, mako, pycuda\n",
            "Successfully installed mako-1.3.7 pycuda-2024.1.2 pytools-2024.1.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +\n",
        "#1) INITIALISATION\n",
        "#+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +\n",
        "\n",
        "import numpy as np\n",
        "import pycuda\n",
        "from pycuda import driver, compiler, gpuarray, tools\n",
        "import time\n",
        "\n",
        "# -- initialize the device\n",
        "import pycuda.autoinit\n",
        "\n",
        "\n",
        "#get device information\n",
        "MyDevice=pycuda.driver.Device(0)\n",
        "attributes=MyDevice.get_attributes()\n",
        "\n",
        "for attribute in list(attributes.keys()):\n",
        "  print(str(attribute)+\": \"+str(attributes[attribute]))\n"
      ],
      "metadata": {
        "id": "xSFJQZDX09wG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e5f48aa-50c1-42a0-9e5f-5584a13824c7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ASYNC_ENGINE_COUNT: 3\n",
            "CAN_MAP_HOST_MEMORY: 1\n",
            "CAN_USE_HOST_POINTER_FOR_REGISTERED_MEM: 1\n",
            "CLOCK_RATE: 1590000\n",
            "COMPUTE_CAPABILITY_MAJOR: 7\n",
            "COMPUTE_CAPABILITY_MINOR: 5\n",
            "COMPUTE_MODE: DEFAULT\n",
            "COMPUTE_PREEMPTION_SUPPORTED: 1\n",
            "CONCURRENT_KERNELS: 1\n",
            "CONCURRENT_MANAGED_ACCESS: 1\n",
            "DIRECT_MANAGED_MEM_ACCESS_FROM_HOST: 0\n",
            "ECC_ENABLED: 1\n",
            "GENERIC_COMPRESSION_SUPPORTED: 0\n",
            "GLOBAL_L1_CACHE_SUPPORTED: 1\n",
            "GLOBAL_MEMORY_BUS_WIDTH: 256\n",
            "GPU_OVERLAP: 1\n",
            "HANDLE_TYPE_POSIX_FILE_DESCRIPTOR_SUPPORTED: 1\n",
            "HANDLE_TYPE_WIN32_HANDLE_SUPPORTED: 0\n",
            "HANDLE_TYPE_WIN32_KMT_HANDLE_SUPPORTED: 0\n",
            "HOST_NATIVE_ATOMIC_SUPPORTED: 0\n",
            "INTEGRATED: 0\n",
            "KERNEL_EXEC_TIMEOUT: 0\n",
            "L2_CACHE_SIZE: 4194304\n",
            "LOCAL_L1_CACHE_SUPPORTED: 1\n",
            "MANAGED_MEMORY: 1\n",
            "MAXIMUM_SURFACE1D_LAYERED_LAYERS: 2048\n",
            "MAXIMUM_SURFACE1D_LAYERED_WIDTH: 32768\n",
            "MAXIMUM_SURFACE1D_WIDTH: 32768\n",
            "MAXIMUM_SURFACE2D_HEIGHT: 65536\n",
            "MAXIMUM_SURFACE2D_LAYERED_HEIGHT: 32768\n",
            "MAXIMUM_SURFACE2D_LAYERED_LAYERS: 2048\n",
            "MAXIMUM_SURFACE2D_LAYERED_WIDTH: 32768\n",
            "MAXIMUM_SURFACE2D_WIDTH: 131072\n",
            "MAXIMUM_SURFACE3D_DEPTH: 16384\n",
            "MAXIMUM_SURFACE3D_HEIGHT: 16384\n",
            "MAXIMUM_SURFACE3D_WIDTH: 16384\n",
            "MAXIMUM_SURFACECUBEMAP_LAYERED_LAYERS: 2046\n",
            "MAXIMUM_SURFACECUBEMAP_LAYERED_WIDTH: 32768\n",
            "MAXIMUM_SURFACECUBEMAP_WIDTH: 32768\n",
            "MAXIMUM_TEXTURE1D_LAYERED_LAYERS: 2048\n",
            "MAXIMUM_TEXTURE1D_LAYERED_WIDTH: 32768\n",
            "MAXIMUM_TEXTURE1D_LINEAR_WIDTH: 268435456\n",
            "MAXIMUM_TEXTURE1D_MIPMAPPED_WIDTH: 32768\n",
            "MAXIMUM_TEXTURE1D_WIDTH: 131072\n",
            "MAXIMUM_TEXTURE2D_ARRAY_HEIGHT: 32768\n",
            "MAXIMUM_TEXTURE2D_ARRAY_NUMSLICES: 2048\n",
            "MAXIMUM_TEXTURE2D_ARRAY_WIDTH: 32768\n",
            "MAXIMUM_TEXTURE2D_GATHER_HEIGHT: 32768\n",
            "MAXIMUM_TEXTURE2D_GATHER_WIDTH: 32768\n",
            "MAXIMUM_TEXTURE2D_HEIGHT: 65536\n",
            "MAXIMUM_TEXTURE2D_LINEAR_HEIGHT: 65000\n",
            "MAXIMUM_TEXTURE2D_LINEAR_PITCH: 2097120\n",
            "MAXIMUM_TEXTURE2D_LINEAR_WIDTH: 131072\n",
            "MAXIMUM_TEXTURE2D_MIPMAPPED_HEIGHT: 32768\n",
            "MAXIMUM_TEXTURE2D_MIPMAPPED_WIDTH: 32768\n",
            "MAXIMUM_TEXTURE2D_WIDTH: 131072\n",
            "MAXIMUM_TEXTURE3D_DEPTH: 16384\n",
            "MAXIMUM_TEXTURE3D_DEPTH_ALTERNATE: 32768\n",
            "MAXIMUM_TEXTURE3D_HEIGHT: 16384\n",
            "MAXIMUM_TEXTURE3D_HEIGHT_ALTERNATE: 8192\n",
            "MAXIMUM_TEXTURE3D_WIDTH: 16384\n",
            "MAXIMUM_TEXTURE3D_WIDTH_ALTERNATE: 8192\n",
            "MAXIMUM_TEXTURECUBEMAP_LAYERED_LAYERS: 2046\n",
            "MAXIMUM_TEXTURECUBEMAP_LAYERED_WIDTH: 32768\n",
            "MAXIMUM_TEXTURECUBEMAP_WIDTH: 32768\n",
            "MAX_BLOCKS_PER_MULTIPROCESSOR: 16\n",
            "MAX_BLOCK_DIM_X: 1024\n",
            "MAX_BLOCK_DIM_Y: 1024\n",
            "MAX_BLOCK_DIM_Z: 64\n",
            "MAX_GRID_DIM_X: 2147483647\n",
            "MAX_GRID_DIM_Y: 65535\n",
            "MAX_GRID_DIM_Z: 65535\n",
            "MAX_PERSISTING_L2_CACHE_SIZE: 0\n",
            "MAX_PITCH: 2147483647\n",
            "MAX_REGISTERS_PER_BLOCK: 65536\n",
            "MAX_REGISTERS_PER_MULTIPROCESSOR: 65536\n",
            "MAX_SHARED_MEMORY_PER_BLOCK: 49152\n",
            "MAX_SHARED_MEMORY_PER_BLOCK_OPTIN: 65536\n",
            "MAX_SHARED_MEMORY_PER_MULTIPROCESSOR: 65536\n",
            "MAX_THREADS_PER_BLOCK: 1024\n",
            "MAX_THREADS_PER_MULTIPROCESSOR: 1024\n",
            "MEMORY_CLOCK_RATE: 5001000\n",
            "MEMORY_POOLS_SUPPORTED: 1\n",
            "MULTIPROCESSOR_COUNT: 40\n",
            "MULTI_GPU_BOARD: 0\n",
            "MULTI_GPU_BOARD_GROUP_ID: 0\n",
            "PAGEABLE_MEMORY_ACCESS: 0\n",
            "PAGEABLE_MEMORY_ACCESS_USES_HOST_PAGE_TABLES: 0\n",
            "PCI_BUS_ID: 0\n",
            "PCI_DEVICE_ID: 4\n",
            "PCI_DOMAIN_ID: 0\n",
            "READ_ONLY_HOST_REGISTER_SUPPORTED: 1\n",
            "RESERVED_SHARED_MEMORY_PER_BLOCK: 0\n",
            "SINGLE_TO_DOUBLE_PRECISION_PERF_RATIO: 32\n",
            "STREAM_PRIORITIES_SUPPORTED: 1\n",
            "SURFACE_ALIGNMENT: 512\n",
            "TCC_DRIVER: 0\n",
            "TEXTURE_ALIGNMENT: 512\n",
            "TEXTURE_PITCH_ALIGNMENT: 32\n",
            "TOTAL_CONSTANT_MEMORY: 65536\n",
            "UNIFIED_ADDRESSING: 1\n",
            "WARP_SIZE: 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +\n",
        "#2) MATRIX MULTIPLICATION ON THE CPU\n",
        "#+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +\n",
        "\n",
        "# define the (square) matrix size\n",
        "#  note that we'll only use *one* block of threads here\n",
        "#  as a consequence this number (squared) can't exceed max_threads\n",
        "# -> use MyDevice.get_attributes() to get this information\n",
        "MATRIX_SIZE = 128\n",
        "\n",
        "# create two random square matrices\n",
        "a_cpu = np.random.randn(MATRIX_SIZE, MATRIX_SIZE).astype(np.float32)\n",
        "b_cpu = np.random.randn(MATRIX_SIZE, MATRIX_SIZE).astype(np.float32)\n",
        "\n",
        "# compute reference on the CPU to verify GPU computation\n",
        "time_start=time.time()\n",
        "c_cpu = np.dot(a_cpu, b_cpu)\n",
        "time_end=time.time()\n",
        "print('enlapsed time (CPU):',time_end-time_start,' seconds')\n",
        "\n"
      ],
      "metadata": {
        "id": "PSOfAZxI1BBA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "217d21b2-e713-448d-d211-bf7bcf0e2aa9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enlapsed time (CPU): 0.007005929946899414  seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +\n",
        "#3) MAKE AND COMPILE THE KERNEL FOR MATRIX MULTIPLICATION ON THE GPU\n",
        "#+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +\n",
        "\n",
        "#define the kernel (for the meaning of %()s, see: https://stackoverflow.com/questions/63862118/what-is-the-meaning-of-s-in-python)\n",
        "kernel_code_templates = \"\"\"\n",
        "__global__ void MatrixMulKernel_sequential(float *a, float *b, float *c)\n",
        "{\n",
        "    for (int i = 0; i < %(MATRIX_SIZE)s; ++i) {\n",
        "      for (int j = 0; j < %(MATRIX_SIZE)s; ++j) {\n",
        "        c[i * %(MATRIX_SIZE)s + j] = 0.;\n",
        "        for (int k = 0; k < %(MATRIX_SIZE)s; ++k) {\n",
        "          c[i * %(MATRIX_SIZE)s + j] += a[i * %(MATRIX_SIZE)s + k] * b[k * %(MATRIX_SIZE)s + j];\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "}\n",
        "__global__ void MatrixMulKernel_sequential2(float *a, float *b, float *c)\n",
        "{\n",
        "    float c_value;\n",
        "\n",
        "    for (int i = 0; i < %(MATRIX_SIZE)s; ++i) {\n",
        "      for (int j = 0; j < %(MATRIX_SIZE)s; ++j) {\n",
        "        c_value = 0.;\n",
        "        for (int k = 0; k < %(MATRIX_SIZE)s; ++k) {\n",
        "          c_value += a[i * %(MATRIX_SIZE)s + k] * b[k * %(MATRIX_SIZE)s + j];\n",
        "        }\n",
        "        c[i * %(MATRIX_SIZE)s + j]=c_value;\n",
        "      }\n",
        "    }\n",
        "}\n",
        "__global__ void MatrixMulKernel_parallel(float *a, float *b, float *c)\n",
        "{\n",
        "    int tx = threadIdx.x;\n",
        "    int ty = threadIdx.y;\n",
        "\n",
        "    // Pvalue is used to store the element of the matrix\n",
        "    // that is computed by the thread\n",
        "    float Pvalue = 0;\n",
        "\n",
        "    // Each thread loads one row of M and one column of N,\n",
        "    //   to produce one element of P.\n",
        "    for (int k = 0; k < %(MATRIX_SIZE)s; ++k) {\n",
        "        Pvalue += a[ty * %(MATRIX_SIZE)s + k] * b[k * %(MATRIX_SIZE)s + tx];\n",
        "    }\n",
        "\n",
        "    // Write the matrix to device memory;\n",
        "    // each thread writes one element\n",
        "    c[ty * %(MATRIX_SIZE)s + tx] = Pvalue;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# get the kernel code from the template\n",
        "# by specifying the constant MATRIX_SIZE\n",
        "kernel_codes = kernel_code_templates % {\n",
        "    'MATRIX_SIZE': MATRIX_SIZE\n",
        "    }\n",
        "\n",
        "# compile the kernel code\n",
        "mod = compiler.SourceModule(kernel_codes)\n",
        "\n",
        "# get the kernel function from the compiled module\n",
        "matrixmul_sequential = mod.get_function(\"MatrixMulKernel_sequential\")\n",
        "matrixmul_sequential2 = mod.get_function(\"MatrixMulKernel_sequential2\")\n",
        "matrixmul_parallel = mod.get_function(\"MatrixMulKernel_parallel\")\n"
      ],
      "metadata": {
        "id": "bmfP4Z_S1EtR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +\n",
        "#4) MATRIX MULTIPLICATION ON THE GPU\n",
        "#+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +\n",
        "\n",
        "\n",
        "# transfer host (CPU) memory to device (GPU) memory\n",
        "a_gpu = gpuarray.to_gpu(a_cpu)\n",
        "b_gpu = gpuarray.to_gpu(b_cpu)\n",
        "\n",
        "# create empty gpu array for the result (C = A * B)\n",
        "c_gpu = gpuarray.empty((MATRIX_SIZE, MATRIX_SIZE), np.float32)\n",
        "\n",
        "\n",
        "\n",
        "# call the kernel on the card -- sequential matrix multiplication\n",
        "time_start=time.time()\n",
        "matrixmul_sequential(a_gpu , b_gpu , c_gpu , block = (1, 1, 1))\n",
        "time_end=time.time()\n",
        "\n",
        "print('enlapsed time (GPU - sequential):',time_end-time_start,' seconds')\n",
        "print('norm(c_cpu-c_gpu)='+str(np.linalg.norm(c_cpu - c_gpu.get())))\n",
        "\n",
        "# call the kernel on the card -- sequential (slighly improved) matrix multiplication\n",
        "time_start=time.time()\n",
        "matrixmul_sequential2(a_gpu , b_gpu , c_gpu , block = (1, 1, 1))\n",
        "time_end=time.time()\n",
        "\n",
        "print('enlapsed time (GPU - sequential 2):',time_end-time_start,' seconds')\n",
        "print('norm(c_cpu-c_gpu)='+str(np.linalg.norm(c_cpu - c_gpu.get())))\n",
        "\n",
        "\n",
        "# call the kernel on the card\n",
        "time_start=time.time()\n",
        "matrixmul_parallel(a_gpu, b_gpu, c_gpu, block = (MATRIX_SIZE, MATRIX_SIZE, 1))\n",
        "time_end=time.time()\n",
        "print('enlapsed time (GPU - parallel):',time_end-time_start,' seconds')\n",
        "print('norm(c_cpu-c_gpu)='+str(np.linalg.norm(c_cpu - c_gpu.get())))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZgJ9fw5T1Iz_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "outputId": "ff5618e7-1d40-41da-a7e2-3770f5fc3839"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enlapsed time (GPU - sequential): 0.0002510547637939453  seconds\n",
            "norm(c_cpu-c_gpu)=0.00016191135\n",
            "enlapsed time (GPU - sequential 2): 0.0001895427703857422  seconds\n",
            "norm(c_cpu-c_gpu)=0.00016191135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/google/colab/_variable_inspector.py:27: UserWarning: device_allocation in out-of-thread context could not be cleaned up\n",
            "  globals().clear()\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "LogicError",
          "evalue": "cuFuncSetBlockShape failed: invalid argument",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLogicError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-b25220731a2e>\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# call the kernel on the card\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mmatrixmul_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mMATRIX_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMATRIX_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0mtime_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'enlapsed time (GPU - parallel):'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime_end\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtime_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' seconds'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pycuda/driver.py\u001b[0m in \u001b[0;36mfunction_call\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"must specify block size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m         \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_block_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m         \u001b[0mhandlers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_buf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_build_arg_buf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLogicError\u001b[0m: cuFuncSetBlockShape failed: invalid argument"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##QUESTION 1\n",
        "Comprenez bien chaque partie du code en vous attardant sur :\n",
        "- 1.1 :les commandes utilisees pour ecrire, compiler et executer les differents noyaux (kernels)\n",
        "- 1.2 : le lien entre les algorithmes implémentés dans les differents noyaux utilises et la taille des blocs lors de leur appel.\n",
        "\n",
        "##QUESTION 2\n",
        "Comparez les temps de calucul entre la multiplication CPU et celles GPU (relancez plusieurs fois les calculs car les temps d'execution peuvent etres très variables d'une fois sur l'autre en fonction de l'utilisation du PC/serveur. Gardez alors les temps les plus courts). Il est tout a fait possible que les gains ne soient pas bons (ce sera moins le cas dans les exercices 2 et 3 avec des algorithmes plus adaptes au GPU). Pourquoi ?\n",
        "             \n",
        "##QUESTION 3\n",
        "Comparez les temps de calculs entre la methode 'sequential' et celle 'sequential 2'. Pourquoi la seconde est un peu plus rapide ?\n",
        "             \n",
        "##QUESTION 4\n",
        "Comparez les temps de calculs entre la methode 'sequential' et celle 'parallel'. Pourquoi les gains sont si faibles (voir negatifs) alors que les calculs on ete parallelises sur 1024 noeuds ?\n",
        "             \n",
        "##QUESTION 5\n",
        "Il est très clair que les calculs parallélisés sur chaque noeud sont trop court avec une matrice de taille 32x32 par rapport au temps perdu a deplacer l'information et a ordonancer la parallelisation. Relancez alors les calculs avec une taille de matrice plus grande (disons 128x128). Pourquoi cela ne marche pas ?\n",
        "\n",
        "La réponse va en tous cas nous motiver a utiliser dans l'exercice 2 une grille de blocs et non un seul bloc... ce qui va rendre les gains de temps bien plus interessants !\n"
      ],
      "metadata": {
        "id": "vA33MeF61OSI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mbv1sidLimy4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}